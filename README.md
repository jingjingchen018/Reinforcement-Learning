# Reinforcement Learning: Theory and Algorithms

## Slides and notes  of Alessandro Lazaric (more theory)

http://researchers.lille.inria.fr/~lazaric/Webpage/MVA-RL_Course16.html

![image-20201012200734241](/Users/chenjingjing/Library/Application Support/typora-user-images/image-20201012200734241.png)

## Slides of RLChina

https://rlchina.org 

Slides related to RL 

## Slides of 

## Slides of Zhou Bolei

more basic

https://github.com/zhoubolei/introRL
=======
## the RL working draft

The second chapter of this RL working draft aims to characterize the optimal minimax sample complexity of estimating the optimal state-action value $Q^{\star}$ with a generative model $\hat{P}$. To get a better understanding about the content of this chapter, I read three articles about it. 

## Papers I have read

[1]Du S S, Kakade S M, Wang R, et al. Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning?[J]. arXiv preprint arXiv:1910.03016, 2019.

#### 1.1 the major contributions
from this article, I know the motivation of the 2nd Chapter of the working draft of RL. There is an useful link about this article https://www.youtube.com/watch?v=i63WoK852q0
#### Comments
I read the abstract and the introduction of this paper, meanwhile, watched the video. 


the main content of Chapter2 comes from the work of Azar et al.

[2]Azar M G, Munos R, Kappen H J. Minimax PAC bounds on the sample complexity of reinforcement learning with a generative model[J]. Machine learning, 2013, 91(3): 325-349.

#### 1.2 the major contributions
The main objective of this paper is to estimate the bound of the estimating the error between the optimal action value function and the estimated action value function.
#### Comments
I have proved half of this article.

[3]Satinder Singh and Richard Yee. An upper bound on the loss from approximate optimal-value functions. Machine Learning, 16(3):227–233, 1994.

#### 1.3 the major contributions
This article derived an upper bound on the performance loss which measured the error between the optimal value function（the optimal action value function） and the estimated value function based on the greedy policy. 
#### Comments
A fundamental result used in the second article. 

>>>>>>> 23f3c253ffc6ab7e89a9d7c7d319ca3255c24d37

